{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import argrelextrema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define colors\n",
    "bull_css = '#169400'\n",
    "bull_avg_css = '#9598a1'\n",
    "bear_css = '#ff1100'\n",
    "bear_avg_css = '#9598a1'\n",
    "\n",
    "# Define line styles\n",
    "line_styles = {'⎯⎯⎯': '-', '----': '--', '····': ':'}\n",
    "\n",
    "# Define input parameters\n",
    "length = 5\n",
    "bull_ext_last = 3\n",
    "bear_ext_last = 3\n",
    "line_style = '⎯⎯⎯'\n",
    "line_width = 1\n",
    "mitigation = \"Wick\"#'Close' #['Wick', 'Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv_path = \"data/GBPUSD_3Y_H1_OHLCV.csv\"\n",
    "csv_path = \"data/TV_OBD_Export_GBPUSD_h1.csv\"\n",
    "date_parser = lambda x: pd.to_datetime(x, unit='s')\n",
    "# df = pd.read_csv(csv_path, parse_dates=['time'], date_parser=date_parser)\n",
    "df = pd.read_csv(csv_path, parse_dates=['time'], usecols= ['time', 'open', 'high', 'low', 'close', 'Volume'],date_parser=date_parser)\n",
    "data = df.copy()\n",
    "data['hl2'] = (data['high'] + data['low']) / 2\n",
    "# data = data[data['time'].dt.dayofweek < 5]\n",
    "# data.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to convert datetime to UNIX timestamp\n",
    "def convert_to_unix(df, column):\n",
    "    df[column] = (df[column] - pd.Timestamp(\"1970-01-01\")) // pd.Timedelta('1s')\n",
    "    return df[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['time'] = pd.to_datetime(data['time'])\n",
    "data['time'] = convert_to_unix(data, column = 'time')\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def np_shift(a:np.ndarray, shift_value:int, axis=0, fill_value=np.NaN) -> np.ndarray:\n",
    "    if shift_value == 0:\n",
    "        return a\n",
    "    \n",
    "    if not np.issubdtype(a.dtype, np.floating):\n",
    "        a = a.astype(np.float64)\n",
    "    \n",
    "    result = np.roll(a=a, shift=shift_value, axis=axis)\n",
    "    axes = [slice(None)] * a.ndim\n",
    "    if shift_value > 0:\n",
    "        axes[axis] = slice(None, shift_value)\n",
    "    else:\n",
    "        axes[axis] = slice(shift_value, None)\n",
    "\n",
    "    result[tuple(axes)] = fill_value\n",
    "\n",
    "    return result\n",
    "\n",
    "def pivothigh(data, left_length, right_length):\n",
    "    \"\"\"\n",
    "    Find pivot highs in a numpy array.\n",
    "\n",
    "    Parameters:\n",
    "    data (numpy.array): Array containing the data\n",
    "    left_bars (int): Number of bars to the left of the pivot\n",
    "    right_bars (int): Number of bars to the right of the pivot\n",
    "\n",
    "    Returns:\n",
    "    numpy.array: An array where each pivot high is marked with the value of the pivot, and non-pivots are np.nan\n",
    "    \"\"\"\n",
    "    # Use scipy's argrelextrema function to find the indices of relative highs\n",
    "    pivot_indices = argrelextrema(data, np.greater_equal, order=max(left_length, right_length))\n",
    "\n",
    "    # Create an array of np.nan\n",
    "    pivot_array = np.full(data.shape, np.nan)\n",
    "\n",
    "    # Set the values at the pivot indices to the values from the data array\n",
    "    pivot_array[pivot_indices] = data[pivot_indices]\n",
    "\n",
    "    if left_length == right_length:\n",
    "        final_array = np_shift(pivot_array, left_length, fill_value= 0)\n",
    "    else:\n",
    "        final_array = pivot_array\n",
    "    return final_array\n",
    "\n",
    "# Example usage:\n",
    "volume_test_data = np.array([100.0, 259.0, 368.0, 249.1, 79.2, 212.0, 390.0, 212.1, 105.0])  # Replace this with your volume data\n",
    "\n",
    "# phv = pivothigh(volume_test_data, left_length = 2, right_length = 2)\n",
    "phv = pivothigh(volume_test_data, 2, 2)\n",
    "print(phv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = pd.Series([1, 2, 3, 4, 5])\n",
    "shifted_s = s.shift(2)\n",
    "shifted_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.array([1, 2, 3, 4, 5])\n",
    "np_shift(s,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get coordinates\n",
    "# def get_coordinates(condition, top, btm, ob_val, time_stamps):\n",
    "#     ob_top  = []\n",
    "#     ob_btm  = []\n",
    "#     ob_avg  = []\n",
    "#     ob_left = []\n",
    "\n",
    "#     ob = None\n",
    "#     # Append coordinates to lists\n",
    "#     if condition:\n",
    "#         avg = (top + btm) / 2.0\n",
    "        \n",
    "#         ob_top.insert(0, top)\n",
    "#         ob_btm.insert(0, btm)\n",
    "#         ob_avg.insert(0, avg)\n",
    "#         ob_left.insert(0, time_stamps)\n",
    "        \n",
    "#         ob = ob_val\n",
    "    \n",
    "#     return ob_top, ob_btm, ob_avg, ob_left, ob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_mitigated(ob_top, ob_btm, ob_left, ob_avg, target, bull):\n",
    "    mitigated = False\n",
    "    target_array = ob_btm if bull else ob_top\n",
    "\n",
    "    for element in target_array:\n",
    "        idx = target_array.index(element)\n",
    "\n",
    "        if ((bull and (target < element).any()) or (not bull and (target > element).any())):  # or .all(), depending on your needs\n",
    "            mitigated = True\n",
    "\n",
    "            del ob_top[idx]\n",
    "            del ob_btm[idx]\n",
    "            del ob_avg[idx]\n",
    "            del ob_left[idx]\n",
    "\n",
    "    return mitigated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main logic\n",
    "data['upper'] = data['high'].rolling(window=length).max()\n",
    "data['lower'] = data['low'].rolling(window=length).min()\n",
    "\n",
    "if mitigation == 'Close':\n",
    "    data['target_bull'] = data['close'].rolling(window=length).min()\n",
    "    data['target_bear'] = data['close'].rolling(window=length).max()\n",
    "else:\n",
    "    data['target_bull'] = data['lower']\n",
    "    data['target_bear'] = data['upper']\n",
    "\n",
    "data['os'] = np.where(data['high'].shift(length) > data['upper'], 0, np.where(data['low'].shift(length) < data['lower'], 1, np.nan))\n",
    "data['os'].ffill(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.loc[:,'phv'] = data['Volume'].rolling(window=length * 2 + 1, center=True).max() == data['Volume']\n",
    "data['phv'] = pivothigh(data['Volume'].to_numpy(), left_length = length, right_length = length)\n",
    "# data.iloc[:, -5:].tail() # Last 5 cols\n",
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[~data['phv'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.dropna(subset = ['os'],inplace = True)\n",
    "# data['os'] = data['os'].astype(int)\n",
    "# data.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = data.iloc[:100]\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_coordinates(row, length):\n",
    "#     # import pdb; pdb.set_trace()\n",
    "#     condition = (row['phv'] > 1) and (row['os'] == 1)\n",
    "#     top = row['hl2']\n",
    "#     btm = ob_val = row['low']\n",
    "#     time_stamps = row['time']\n",
    "#     ob_top  = []\n",
    "#     ob_btm  = []\n",
    "#     ob_avg  = []\n",
    "#     ob_left = []\n",
    "\n",
    "#     ob = None\n",
    "#     # Append coordinates to lists\n",
    "#     if condition:\n",
    "#         avg = (top + btm) / 2.0\n",
    "        \n",
    "#         ob_top.insert(0, top)\n",
    "#         ob_btm.insert(0, btm)\n",
    "#         ob_avg.insert(0, avg)\n",
    "#         ob_left.insert(0, time_stamps)\n",
    "#         ob = ob_val\n",
    "    \n",
    "#     return ob_top, ob_btm, ob_avg, ob_left, ob\n",
    "\n",
    "# def get_coordinates(row, length, col_names):\n",
    "#     condition = (row['phv'] > 1) and (row['os'] == 1)\n",
    "#     top = row['hl2']\n",
    "#     btm = ob_val = row['low']\n",
    "#     time_stamps = row['time']\n",
    "\n",
    "#     ob_top = ob_btm = ob_avg = ob_left = ob = None\n",
    "\n",
    "#     # Assign values to variables if condition is met\n",
    "#     if condition:\n",
    "#         avg = (top + btm) / 2.0\n",
    "        \n",
    "#         ob_top = top\n",
    "#         ob_btm = btm\n",
    "#         ob_avg = avg\n",
    "#         ob_left = time_stamps\n",
    "#         ob = ob_val\n",
    "    \n",
    "#     return pd.Series([ob_top, ob_btm, ob_avg, ob_left, ob], index=col_names)\n",
    "\n",
    "def get_bullish_coordinates(row, length):\n",
    "    bull_top = bull_btm = bull_avg = bull_left = bull_ob = np.nan\n",
    "\n",
    "    # Compute bullish coordinates\n",
    "    if (row['phv'] != None) and row['os'] == 1:\n",
    "        avg = (row['hl2'] + row['low']) / 2\n",
    "\n",
    "        bull_top = row['hl2']\n",
    "        bull_btm = row['low']\n",
    "        bull_avg = avg\n",
    "        bull_left = row['time']\n",
    "        bull_ob = row['low']\n",
    "\n",
    "    return pd.Series([bull_top, bull_btm, bull_avg, bull_left, bull_ob])\n",
    "\n",
    "def get_bearish_coordinates(row, length):\n",
    "    bear_top = bear_btm = bear_avg = bear_left = bear_ob = np.nan\n",
    "\n",
    "    # Compute bearish coordinates\n",
    "    if (row['phv'] != None) and row['os'] == 0:\n",
    "        avg = (row['high'] + row['hl2']) / 2\n",
    "\n",
    "        bear_top = row['high']\n",
    "        bear_btm = row['hl2']\n",
    "        bear_avg = avg\n",
    "        bear_left = row['time']\n",
    "        bear_ob = row['high']\n",
    "\n",
    "    return pd.Series([bear_top, bear_btm, bear_avg, bear_left, bear_ob])\n",
    "\n",
    "\n",
    "\n",
    "# Apply the function to each row\n",
    "# results = data.shift(length).apply(get_coordinates, axis=1, args=(length,))\n",
    "\n",
    "# Apply the function to each row\n",
    "# results = data.apply(get_coordinates, axis=1, args=(length,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results = pd.DataFrame(results.tolist(), columns=['bull_top', 'bull_btm', 'bull_avg', 'bull_left', 'bull_ob'])\n",
    "# Apply the function to each row\n",
    "# data[['bull_top', 'bull_btm', 'bull_avg', 'bull_left', 'bull_ob']] = data.apply(get_bullish_coordinates, axis=1, args=(length,))\n",
    "# data[['bear_top', 'bear_btm', 'bear_avg', 'bear_left', 'bear_ob']] = data.apply(get_bearish_coordinates, axis=1, args=(length,))\n",
    "# data.to_csv(\"data/GU_TV_Export_FE.csv\", index = False)\n",
    "# data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bullish_coordinates(row):\n",
    "    bull_top = bull_btm = bull_avg = bull_left = bull_ob = np.nan\n",
    "\n",
    "    # Compute bullish coordinates\n",
    "    if row['phv'] != None and row['os'] == 1:\n",
    "        avg = (row['hl2_shifted'] + row['low_shifted']) / 2\n",
    "\n",
    "        bull_top = row['hl2_shifted']\n",
    "        bull_btm = row['low_shifted']\n",
    "        bull_avg = avg\n",
    "        bull_left = row['time_shifted']\n",
    "        bull_ob = row['low_shifted']\n",
    "\n",
    "    return pd.Series([bull_top, bull_btm, bull_avg, bull_left, bull_ob])\n",
    "\n",
    "def get_bearish_coordinates(row):\n",
    "    bear_top = bear_btm = bear_avg = bear_left = bear_ob = np.nan\n",
    "\n",
    "    # Compute bearish coordinates\n",
    "    if row['phv'] != None and row['os'] == 0:\n",
    "        avg = (row['high_shifted'] + row['hl2_shifted']) / 2\n",
    "\n",
    "        bear_top = row['high_shifted']\n",
    "        bear_btm = row['hl2_shifted']\n",
    "        bear_avg = avg\n",
    "        bear_left = row['time_shifted']\n",
    "        bear_ob = row['high_shifted']\n",
    "\n",
    "    return pd.Series([bear_top, bear_btm, bear_avg, bear_left, bear_ob])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['hl2_shifted'] = data['hl2'].shift(length)\n",
    "data['low_shifted'] = data['low'].shift(length)\n",
    "data['high_shifted'] = data['high'].shift(length)\n",
    "data['time_shifted'] = data['time'].shift(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[['bull_top', 'bull_btm', 'bull_avg', 'bull_left', 'bull_ob']] = data.apply(get_bullish_coordinates, axis=1)\n",
    "data[['bear_top', 'bear_btm', 'bear_avg', 'bear_left', 'bear_ob']] = data.apply(get_bearish_coordinates, axis=1)\n",
    "data.to_csv(\"data/GU_TV_data_Python_FeatureEngineered.csv\", index = False)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[~data[\"bull_ob\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[~data[\"bear_ob\"].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vbt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
